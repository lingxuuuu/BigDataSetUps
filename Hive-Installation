Hive Installation
-----------------


1. Download Hive software(apache-hive-2.3.4-bin.tar.gz) from apache
Link: https://archive.apache.org/dist/hive/hive-2.3.4/


2. Move the file to /usr/local/software and extract it. Move the extracted file to /usr/local/hadoop-ecosystems and rename it as hive-2.3.4-bin


3. Goto /usr/local/hadoop-ecosystems/hive-2.3.4-bin/conf and Copy paste hive-default.xml.template file
and rename the new file as hive-site.xml


4.Edit ~/.bashrc file and add HIVE configurations.

//Use $echo $HIVE_HOME to check the home for HIVE files
export HIVE_HOME=/usr/local/hadoop-ecosystem/hive-2.3.4-bin
export PATH=$PATH:$HIVE_HOME/bin:$HIVE_HOME/sbin


5. Open /usr/local/hadoop-ecosystems/hive-2.3.4-bin/conf/hive-site.xml and remove all the tags and replace it with the below xml information.


<configuration>
 <property>
 <name>javax.jdo.option.ConnectionURL</name>
 <value>jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true&amp;useSSL=false</value>
 <description>Metadata will be stored in MYSql server</description>
 </property>

 <property>
 <name>javax.jdo.option.ConnectionDriverName</name>
 <value>com.mysql.jdbc.Driver</value>
 <description>MySql JDBC Driver class</description>
 </property>

 <property>
 <name>javax.jdo.option.ConnectionUserName</name>
 <value>root</value>
 <description>Username for connecting to MYSql database</description>
 </property>

 <property>
 <name>javax.jdo.option.ConnectionPassword</name>
 <value>root</value>
 <description>Password for connecting to MYSql database</description>
 </property>
 
 <property>
 <name>hive.server2.enable.doAs</name>
 <value>false</value> 
 </property>

</configuration>



6. Install mysql if you do not have MySQL in your system

hadoopapache@Hadoop-Dev:~$ sudo apt-get update
hadoopapache@Hadoop-Dev:~$ sudo apt-get install mysql-server

Enter the password as root when it prompts to enter a password.



7. Login to mysql and check the available default databases.

hadoopapache@Hadoop-Dev:~$ sudo mysql -uroot -proot
mysql> show databases;



8. Install Mysql connector.

$sudo apt-get install libmysql-java



9. Create a softlink for connector in Hive lib directory.
$sudo ln -s /usr/share/java/mysql-connector-java.jar $HIVE_HOME/lib/my-sql-connector-java.jar
(Or you can copy mysql-connector-java-5.1.48.jar and mysql-connector-java-5.1.48-bin.jar 2 files and paste into /usr/local/hadoop-ecosystem/hive-2.3.4-bin/lib/)

9.1. alter the user in mysql

ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY 'root';



10. IMPORT: INSURE THAT THE INSTALL AND CONFIG do not have issues.
Goto /usr/local/hadoop-ecosystems/hive-2.3.4-bin/bin and execute the below command

hadoop@ubuntudev:~$ cd /usr/local/hadoop-ecosystem/hive-2.3.4-bin/bin
hadoopapache@Hadoop-Dev:/usr/local/hadoop-ecosystems/hive-2.3.4-bin/bin$ ./schematool -initSchema -dbType mysql
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hadoop-ecosystem/hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-ecosystem/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:	 jdbc:mysql://localhost:3306/metastore?createDatabaseIfNotExist=true&useSSL=false
Metastore Connection Driver :	 com.mysql.jdbc.Driver
Metastore connection User:	 root
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.mysql.sql
Initialization script completed
schemaTool completed  //This line is important. Once you see schemaTool competed means you have successfully installed the Hive



11. $start-all.sh


12. Enter to the Hive shell(This will take us to the hive prompt): 
hadoop@ubuntudev:~$ hive (enter)
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hadoop-ecosystem/hive-2.3.4-bin/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-ecosystem/hadoop-2.9.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/usr/local/hadoop-ecosystem/hive-2.3.4-bin/lib/hive-common-2.3.4.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> 





Hive Version > 3.1

Remove old guava-jre.jar file in $HIVE_HOME/lib

#cp /usr/local/hadoop-ecosystem/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar $HIVE_HOME/lib

cp /usr/local/hadoop-ecosystem/hadoop-3.1.3/share/hadoop/common/lib/guava-27.0-jre.jar $HIVE_HOME/lib


$HOME_HADOOP/etc/hadoop/conf/mapred-site.xml - Add this configuration

<property>
<name>yarn.app.mapreduce.am.env</name>
<value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
<property>
<name>mapreduce.map.env</name>
<value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
<property>
<name>mapreduce.reduce.env</name>
<value>HADOOP_MAPRED_HOME=$HADOOP_HOME</value>
</property>
 
 
</configuration>



