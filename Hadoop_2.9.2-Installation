1.Create two directories in /usr/local

hadoop@Hadoop-Dev:~$ sudo chmod 777 /usr/local
[sudo] password for hadoop: {hadoop}
hadoop@Hadoop-Dev:~$ cd /usr/local
hadoop@Hadoop-Dev:/usr/local$: mkdir software
hadoop@Hadoop-Dev:/usr/local$: mkdir hadoop-ecosystem


2.Update Ubuntu

hadoop@Hadoop-Dev:/usr/local$ sudo apt-get update


3.Install Java

hadoop@Hadoop-Dev:/usr/local$ sudo apt-get install openjdk-8-jdk


4.Install ssh(Do not required to install in Google cloud)

hadoop@Hadoop-Dev:/usr/local$ sudo apt-get install ssh


5.(Download Hadoop2.9.2(hadoop-2.9.2.tar.gz) software and move it to /usr/local.software directory.)

hadoop@ubuntudev:/usr/local$
cd software

hadoop@ubuntudev:/usr/local/software$
wget https://archive.apache.org/dist/hadoop/core/hadoop-2.9.2/hadoop-2.9.2.tar.gz
(wget above is download the file from the https link)

hadoop@ubuntudev:/usr/local/software$ ls -ltr
{total 357864
-rw-rw-r-- 1 hadoop hadoop 366447449 Jul  2  2020 hadoop-2.9.2.tar.gz}

6.(Move the file hadoop-2.9.2.tar.gz to /usr/local/hadoop-ecosystem directory and extract it.)

hadoop@ubuntudev:/usr/local/software$
cp hadoop-2.9.2.tar.gz /usr/local/hadoop-ecosystem/
(cp is copy, copy hadoop file to hadoop-ecosystem)

hadoop@ubuntudev:/usr/local/software$ cd .. (cd space dot dot)

hadoop@ubuntudev:/usr/local$ cd hadoop-ecosystem
hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ ls -ltr
{total 357864
-rw-rw-r-- 1 hadoop hadoop 366447449 Mar  9 18:20 hadoop-2.9.2.tar.gz}

hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ tar -zxvf hadoop-2.9.2.tar.gz
(extract the hadoop file)

hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ ls -ltr
{total 357868
drwxr-xr-x 9 hadoop hadoop      4096 Nov 13  2018 hadoop-2.9.2
-rw-rw-r-- 1 hadoop hadoop 366447449 Mar  9 18:20 hadoop-2.9.2.tar.gz}

hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ rm hadoop-2.9.2.tar.gz
(rm to remove the tar.gz file because we already extracted the file)

hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ ls -ltr
total 4
drwxr-xr-x 9 hadoop hadoop 4096 Nov 13  2018 hadoop-2.9.2

hadoop@ubuntudev:/usr/local/hadoop-ecosystem$ cd hadoop-2.9.2/
hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2$ ls -ltr
total 152
drwxr-xr-x 4 hadoop hadoop   4096 Nov 13  2018 share
-rw-r--r-- 1 hadoop hadoop   1366 Nov 13  2018 README.txt
-rw-r--r-- 1 hadoop hadoop  15917 Nov 13  2018 NOTICE.txt
-rw-r--r-- 1 hadoop hadoop 106210 Nov 13  2018 LICENSE.txt
drwxr-xr-x 3 hadoop hadoop   4096 Nov 13  2018 lib
drwxr-xr-x 3 hadoop hadoop   4096 Nov 13  2018 etc
drwxr-xr-x 3 hadoop hadoop   4096 Nov 13  2018 sbin
drwxr-xr-x 2 hadoop hadoop   4096 Nov 13  2018 libexec
drwxr-xr-x 2 hadoop hadoop   4096 Nov 13  2018 bin
drwxr-xr-x 2 hadoop hadoop   4096 Nov 13  2018 include

(once you the files above, that means you are correctly installed the hadoop)



7.(Goto /usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop and copy paste the file mapred-site.xml.template and rename it as mapred-site.xml)

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2$ cd etc

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc$ ls -ltr
{ total 4
drwxr-xr-x 2 hadoop hadoop 4096 Nov 13  2018 hadoop }

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc$ cd hadoop

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$ ls -ltr
{ total 160
-rw-r--r-- 1 hadoop hadoop  2697 Nov 13  2018 ssl-server.xml.example
-rw-r--r-- 1 hadoop hadoop  2316 Nov 13  2018 ssl-client.xml.example
-rw-r--r-- 1 hadoop hadoop 14016 Nov 13  2018 log4j.properties
-rw-r--r-- 1 hadoop hadoop 10206 Nov 13  2018 hadoop-policy.xml
-rw-r--r-- 1 hadoop hadoop  2490 Nov 13  2018 hadoop-metrics.properties
-rw-r--r-- 1 hadoop hadoop  2598 Nov 13  2018 hadoop-metrics2.properties
-rw-r--r-- 1 hadoop hadoop  4969 Nov 13  2018 hadoop-env.sh
-rw-r--r-- 1 hadoop hadoop  4133 Nov 13  2018 hadoop-env.cmd
-rw-r--r-- 1 hadoop hadoop   774 Nov 13  2018 core-site.xml
-rw-r--r-- 1 hadoop hadoop   775 Nov 13  2018 hdfs-site.xml
-rw-r--r-- 1 hadoop hadoop    21 Nov 13  2018 httpfs-signature.secret
-rw-r--r-- 1 hadoop hadoop  1657 Nov 13  2018 httpfs-log4j.properties
-rw-r--r-- 1 hadoop hadoop  2230 Nov 13  2018 httpfs-env.sh
-rw-r--r-- 1 hadoop hadoop   620 Nov 13  2018 httpfs-site.xml
-rw-r--r-- 1 hadoop hadoop  5939 Nov 13  2018 kms-site.xml
-rw-r--r-- 1 hadoop hadoop  1788 Nov 13  2018 kms-log4j.properties
-rw-r--r-- 1 hadoop hadoop  3139 Nov 13  2018 kms-env.sh
-rw-r--r-- 1 hadoop hadoop  3518 Nov 13  2018 kms-acls.xml
-rw-r--r-- 1 hadoop hadoop   690 Nov 13  2018 yarn-site.xml
-rw-r--r-- 1 hadoop hadoop  4876 Nov 13  2018 yarn-env.sh
-rw-r--r-- 1 hadoop hadoop  2250 Nov 13  2018 yarn-env.cmd
-rw-r--r-- 1 hadoop hadoop    10 Nov 13  2018 slaves
-rw-r--r-- 1 hadoop hadoop  1211 Nov 13  2018 container-executor.cfg
-rw-r--r-- 1 hadoop hadoop  7861 Nov 13  2018 capacity-scheduler.xml
-rw-r--r-- 1 hadoop hadoop   758 Nov 13  2018 mapred-site.xml.template
-rw-r--r-- 1 hadoop hadoop  4113 Nov 13  2018 mapred-queues.xml.template
-rw-r--r-- 1 hadoop hadoop  1507 Nov 13  2018 mapred-env.sh
-rw-r--r-- 1 hadoop hadoop  1076 Nov 13  2018 mapred-env.cmd
-rw-r--r-- 1 hadoop hadoop  1335 Nov 13  2018 configuration.xsl }


hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
cp mapred-site.xml.template mapred-site.xml
( copy paste the file mapred-site.xml.template and rename it as mapred-site.xml )

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$ ls -ltr
total 164
-rw-r--r-- 1 hadoop hadoop  2697 Nov 13  2018 ssl-server.xml.example
-rw-r--r-- 1 hadoop hadoop  2316 Nov 13  2018 ssl-client.xml.example
-rw-r--r-- 1 hadoop hadoop 14016 Nov 13  2018 log4j.properties
-rw-r--r-- 1 hadoop hadoop 10206 Nov 13  2018 hadoop-policy.xml
-rw-r--r-- 1 hadoop hadoop  2490 Nov 13  2018 hadoop-metrics.properties
-rw-r--r-- 1 hadoop hadoop  2598 Nov 13  2018 hadoop-metrics2.properties
-rw-r--r-- 1 hadoop hadoop  4969 Nov 13  2018 hadoop-env.sh
-rw-r--r-- 1 hadoop hadoop  4133 Nov 13  2018 hadoop-env.cmd
-rw-r--r-- 1 hadoop hadoop   774 Nov 13  2018 core-site.xml
-rw-r--r-- 1 hadoop hadoop   775 Nov 13  2018 hdfs-site.xml
-rw-r--r-- 1 hadoop hadoop    21 Nov 13  2018 httpfs-signature.secret
-rw-r--r-- 1 hadoop hadoop  1657 Nov 13  2018 httpfs-log4j.properties
-rw-r--r-- 1 hadoop hadoop  2230 Nov 13  2018 httpfs-env.sh
-rw-r--r-- 1 hadoop hadoop   620 Nov 13  2018 httpfs-site.xml
-rw-r--r-- 1 hadoop hadoop  5939 Nov 13  2018 kms-site.xml
-rw-r--r-- 1 hadoop hadoop  1788 Nov 13  2018 kms-log4j.properties
-rw-r--r-- 1 hadoop hadoop  3139 Nov 13  2018 kms-env.sh
-rw-r--r-- 1 hadoop hadoop  3518 Nov 13  2018 kms-acls.xml
-rw-r--r-- 1 hadoop hadoop   690 Nov 13  2018 yarn-site.xml
-rw-r--r-- 1 hadoop hadoop  4876 Nov 13  2018 yarn-env.sh
-rw-r--r-- 1 hadoop hadoop  2250 Nov 13  2018 yarn-env.cmd
-rw-r--r-- 1 hadoop hadoop    10 Nov 13  2018 slaves
-rw-r--r-- 1 hadoop hadoop  1211 Nov 13  2018 container-executor.cfg
-rw-r--r-- 1 hadoop hadoop  7861 Nov 13  2018 capacity-scheduler.xml
-rw-r--r-- 1 hadoop hadoop   758 Nov 13  2018 mapred-site.xml.template
-rw-r--r-- 1 hadoop hadoop  4113 Nov 13  2018 mapred-queues.xml.template
-rw-r--r-- 1 hadoop hadoop  1507 Nov 13  2018 mapred-env.sh
-rw-r--r-- 1 hadoop hadoop  1076 Nov 13  2018 mapred-env.cmd
-rw-r--r-- 1 hadoop hadoop  1335 Nov 13  2018 configuration.xsl
-rw-r--r-- 1 hadoop hadoop   758 Mar  9 18:48 mapred-site.xml


8.Goto Terminal and edit bashrc file.
hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
sudo apt-get install nano
(install nano to use the editor)

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
sudo nano ~/.bashrc
(~ means goes to the root. Goes to the root and find bashrc file and open it in nano)


9.Open another new terminal and check if the JAVA is installed.
hadoop@ubuntudev:~$ cd /usr/lib/jvm
hadoop@ubuntudev:/usr/lib/jvm$ ls -ltr
{total 4
lrwxrwxrwx 1 root root   20 Jan 19 19:59 java-1.8.0-openjdk-amd64 -> java-8-openjdk-amd64
drwxr-xr-x 7 root root 4096 Mar  9 17:59 java-8-openjdk-amd64}

(when you see java-8-openjdk-amd64 means Java is succesfully installed in pwd:  /usr/lib/jvm )

10.Enter the below paths in .bashrc file:
( .bashrc file:
~/.bashrc: executed by bash(1) for non-login shells.
# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)
# for examples

# If not running interactively, don't do anything
case $- in
*i*) ;;
*) return;;
esac

# don't put duplicate lines or lines starting with space in the history.
# See bash(1) for more options
HISTCONTROL=ignoreboth

# append to the history file, don't overwrite it
shopt -s histappend

# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)
HISTSIZE=1000
HISTFILESIZE=2000

# check the window size after each command and, if necessary,
# update the values of LINES and COLUMNS.
shopt -s checkwinsize

# If set, the pattern "**" used in a pathname expansion context will
# match all files and zero or more directories and subdirectories.
#shopt -s globstar

# make less more friendly for non-text input files, see lesspipe(1)
[ -x /usr/bin/lesspipe ] && eval "$(SHELL=/bin/sh lesspipe)"

# set variable identifying the chroot you work in (used in the prompt below)
if [ -z "${debian_chroot:-}" ] && [ -r /etc/debian_chroot ]; then
debian_chroot=$(cat /etc/debian_chroot)
fi

# set a fancy prompt (non-color, unless we know we "want" color)
case "$TERM" in
xterm-color|*-256color) color_prompt=yes;;
esac

# uncomment for a colored prompt, if the terminal has the capability; turned
# off by default to not distract the user: the focus in a terminal window
# should be on the output of commands, not on the prompt
#force_color_prompt=yes

if [ -n "$force_color_prompt" ]; then
if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then
# We have color support; assume it's compliant with Ecma-48
# (ISO/IEC-6429). (Lack of such support is extremely rare, and such
# a case would tend to support setf rather than setaf.)
color_prompt=yes
else
color_prompt=
fi
fi

(Add this line of code in the file)
#JAVA path configuration

export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64

export PATH=$PATH:$JAVA_HOME/bin
end of .bashrc file)

After insert the code: Ctrl X to exit, Y to save and enter to exit.

11.hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
sudo nano ~/.bashrc

Copy and Paste the code below into the same .bashrc file

#HADOOP path configuration

export HADOOP_HOME=/usr/local/hadoop-ecosystem/hadoop-2.9.2

#export HADOOP_PREFIX=/usr/local/hadoop-ecosystem/hadoop-2.9.2

export HADOOP_MAPRED_HOME=${HADOOP_HOME}

export HADOOP_COMMON_HOME=${HADOOP_HOME}

export HADOOP_HDFS_HOME=${HADOOP_HOME}

export YARN_HOME=${HADOOP_HOME}

export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/hadoop

# Native Path

export HADOOP_COMMON_LIB_NATIVE_DIR=${HADOOP_HOME}/lib/native

export HADOOP_OPTS="-Djava.library.path=$HADOOP_PREFIX/lib"

export HADOOP_OPTS="-Djava.library.path=$HADOOP_COMMON_LIB_NATIVE_DIR"

# Add Hadoop bin/ directory to PATH

export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

After insert the code: Ctrl X to exit, Y to save and enter to exit.


12.Configuring the HDFS files.
Go to /usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop

They are:

core-site.xml

hdfs-site.xml

mapred-site.xml

hadoop-env.sh

yarn-site.xml



core-site.xml:

nanohadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
nano core-site.xml

<configuration>

<property>
<name>hadoop.tmp.dir</name>
<value>/usr/local/hadoop-ecosystem/hadoop_data/tmp</value>
<description> Parent directory for other temporary directories </description>
</property>

<property>
<name>fs.defaultFS</name>
<value>hdfs://localhost:9000</value>
<description> The name of the default file system </description>
</property>

</configuration>


hdfs-site.xml:
hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
nano hdfs-site.xml

---------------

<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>

<property>
<name>dfs.namenode.name.dir</name>
<value>/usr/local/hadoop-ecosystem/hadoop_data/hdfs/namenode</value>
</property>

<property>
<name>dfs.datanode.data.dir</name>
<value>/usr/local/hadoop-ecosystem/hadoop_data/hdfs/datanode</value>
</property>
</configuration>





mapred-site.xml:
----------------

<configuration>
<property>
<name>mapreduce.framework.name</name>
<value>yarn</value>
</property>
</configuration>


yarn-site.xml:
-----------------

<configuration>
<!-- Site specific YARN configuration properties -->
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce_shuffle</value>
</property>

<property>
<name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>

<property>
<name>yarn.resourcemanager.webapp.address</name>
<value>localhost:8088</value>
</property>

</configuration>

hadoop-env.sh:
--------------
Just we need to update JAVA_HOME(/usr/lib/jvm/java-1.8.0-openjdk-amd64)

# The java implementation to use.
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-amd64



13. To create a password less startup

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$
sudo apt-get install openssh-server openssh-client

Generate a key for the password:
$ssh-keygen -t rsa -P ""

Enter file in which to save the key (/home/hadoop/.ssh/id_rsa): <just enter>

{Your identification has been saved in /home/hadoop/.ssh/id_rsa
Your public key has been saved in /home/hadoop/.ssh/id_rsa.pub}

hadoop@ubuntudev:/usr/local/hadoop-ecosystem/hadoop-2.9.2/etc/hadoop$ cd ~
(Attention: here you must cd to the root first to cat)

hadoop@ubuntudev:~$
cat /home/hadoop/.ssh/id_rsa.pub >> /home/hadoop/.ssh/authorized_keys
(this part need to match where the public key is saved)

hadoop@ubuntudev:~$
sudo chmod 0650 /home/hadoop/.ssh/authorized_keys

(change the permission of the file)


14.Format the disk to hdfs format.
First active the bashrc file:
hadoop@ubuntudev:~$ source ~/.bashrc

hadoop@ubuntudev:~$ hdfs namenode -format

15. Start hdfs and yarn
hadoop@ubuntudev:~$ start-dfs.sh && start-yarn.sh
( Y and Yes)

16. All the below mentioned daemons or processes should be up and running when you execute jps command with some process idâ€™s.

hadoop@ubuntudev:~$ jps

13536 NameNode
14257 NodeManager
13715 DataNode
14101 ResourceManager
15097 Jps
13903 SecondaryNameNode

